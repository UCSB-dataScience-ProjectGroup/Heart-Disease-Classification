{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Divides a set on a specific column. Can handle numeric or nominal values\n",
    "#pseudocode for forming individual trees\n",
    "def divideset(rows,column,value):\n",
    "   # Make a function that tells us if a row is in the first group (true) or the second group (false)\n",
    "   split_function=None\n",
    "   if isinstance(value,int) or isinstance(value,float): # check if the value is a number i.e int or float\n",
    "      split_function=lambda row:row[column]>=value\n",
    "   else:\n",
    "      split_function=lambda row:row[column]==value\n",
    "   \n",
    "   # Divide the rows into two sets and return them\n",
    "   set1=[row for row in rows if split_function(row)]\n",
    "   set2=[row for row in rows if not split_function(row)]\n",
    "   return (set1,set2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Data frames\n",
    "import matplotlib.pyplot as plt # Visuals\n",
    "from sklearn.model_selection import train_test_split # Create training and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier # Kth Nearest Neighbor\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Trees\n",
    "from sklearn.tree import export_graphviz # Extract Decision Tree visual\n",
    "from sklearn import tree #decision trees\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "from sklearn.neural_network import MLPClassifier # Neural Networks\n",
    "from sklearn.metrics import roc_curve # ROC Curves\n",
    "from sklearn.metrics import auc # AUC \n",
    "from urllib.request import urlopen # Get data from UCI Machine Learning Repository\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "Cleveland_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "Hungarian_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "Switzerland_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data'\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)#makes it so that we can see a whole array when we output it\n",
    "\n",
    "names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'heart disease(by angiography)']\n",
    "\n",
    "ClevelandHeartDisease = pd.read_csv(urlopen(Cleveland_data_URL), names = names)#gets Cleveland data\n",
    "HungarianHeartDisease = pd.read_csv(urlopen(Hungarian_data_URL), names = names)#gets Hungary data\n",
    "SwitzerlandHeartDisease = pd.read_csv(urlopen(Switzerland_data_URL), names = names)#gets Switzerland data\n",
    "datatemp = [ClevelandHeartDisease, HungarianHeartDisease, SwitzerlandHeartDisease]#combines all arrays into a list\n",
    "\n",
    "#heartDisease.set_index(['id_number'], inplace = True)\n",
    "#I don't know what that did, but it was from Raoul's code and it was giving me bugs so I got rid of it\n",
    "data = pd.concat(datatemp)#combines list into one array\n",
    "del data['ca']\n",
    "del data['slope']\n",
    "del data['thal']#these delete the columns that have a lot of ? values and so aren't very useful to us\n",
    "\n",
    "data = data.replace('?',np.nan)#convert ? values to np.nan\n",
    "\n",
    "for item in data:#converts everything to floats\n",
    "    data[item] = pd.to_numeric(data[item])\n",
    "\n",
    "def normalize(heartDisease, toNormalize):#normalizes \n",
    "    result = heartDisease.copy()\n",
    "    for item in heartDisease.columns:\n",
    "        if (item in toNormalize):\n",
    "            max_value = heartDisease[item].max()\n",
    "            min_value = heartDisease[item].min()\n",
    "            result[item] = (heartDisease[item] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "toNormalize = ['age', 'cp', 'trestbps', 'chol', 'thalach', 'oldpeak']#columns to normalize\n",
    "data = normalize(data, toNormalize)\n",
    "data = data.dropna()#gets rid of nan values\n",
    "counter = 0\n",
    "for i in range(1,5):#replaces angiography numbers with 1\n",
    "    data['heart disease(by angiography)'] = data['heart disease(by angiography)'].replace(i,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count = 0\n",
    "#for item in data:\n",
    " #   for i in data[item]:\n",
    "  #      count += (i=='?')\n",
    "   # print(count)\n",
    "    #count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train0, test0 = train_test_split(data, test_size = 0.20, random_state = 42)# splits data into test set and train set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train0[['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']], train0['heart disease(by angiography)'])\n",
    "predictions = clf.predict(test0[['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']])\n",
    "predictright = 0\n",
    "predictions.shape[0]\n",
    "for i in range(0,predictions.shape[0]-1):\n",
    "    if (predictions[i]== test0.iloc[i][10]):\n",
    "        predictright +=1\n",
    "rightpercent = predictright/predictions.shape[0]\n",
    "rightpercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#PUTTING TOGETHER A DATASET FOR THE DATABASES THAT DO NOT HAVE ONLY 1S FOR HEART DISEASE\n",
    "datatemp2 = [ClevelandHeartDisease, SwitzerlandHeartDisease]\n",
    "data2 = pd.concat(datatemp2)\n",
    "del data2['ca']\n",
    "del data2['slope']\n",
    "del data2['thal']#these delete the columns that have a lot of ? values and so aren't very useful to us\n",
    "\n",
    "data2 = data2.replace('?',np.nan)#convert ? values to np.nan\n",
    "\n",
    "for item in data2:#converts everything to floats\n",
    "    data2[item] = pd.to_numeric(data2[item])\n",
    "\n",
    "data2 = normalize(data2, toNormalize)\n",
    "data2 = data2.dropna()#gets rid of nan values    \n",
    "train2, test2 = train_test_split(data2, test_size = 0.20, random_state = 42)#splits data into test set and training set\n",
    "\n",
    "#CREATING AND EDITING DATASET FOR JUST HUNGARIAN HEART DISEASE\n",
    "del HungarianHeartDisease['ca']\n",
    "del HungarianHeartDisease['slope']\n",
    "del HungarianHeartDisease['thal']#these delete the columns that have a lot of ? values and so aren't very useful to us\n",
    "HungarianHeartDisease = HungarianHeartDisease.replace('?',np.nan)#convert ? values to np.nan\n",
    "for item in HungarianHeartDisease:#converts everything to floats\n",
    "    HungarianHeartDisease[item] = pd.to_numeric(HungarianHeartDisease[item])\n",
    "HungarianHeartDisease = normalize(HungarianHeartDisease, toNormalize)\n",
    "HungarianHeartDisease = HungarianHeartDisease.dropna()#gets rid of nan values\n",
    "trainH, testH = train_test_split(HungarianHeartDisease, test_size = 0.20, random_state = 42)# splits data into test set and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7169811320754716"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfH = tree.DecisionTreeClassifier()\n",
    "clfH = clfH.fit(trainH[['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']], trainH['heart disease(by angiography)'])\n",
    "predictionsH = clfH.predict(testH[['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']])\n",
    "predictrightH = 0\n",
    "predictionsH.shape[0]\n",
    "for i in range(0,predictionsH.shape[0]-1):\n",
    "    if (predictionsH[i]== testH.iloc[i][10]):\n",
    "        predictrightH +=1\n",
    "rightpercentH = predictrightH/predictionsH.shape[0]\n",
    "rightpercentH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967741935483871"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = tree.DecisionTreeClassifier()\n",
    "clf2 = clf2.fit(train2[['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']], train2['heart disease(by angiography)'])\n",
    "predictions2 = clf2.predict(test2[['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']])\n",
    "predictright2 = 0\n",
    "for i in range(0,predictions2.shape[0]-1):\n",
    "    if (predictions2[i]== test2.iloc[i][10]):\n",
    "        predictright2 +=1\n",
    "rightpercent2 = predictright2/predictions2.shape[0]\n",
    "rightpercent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 3, 0, 1, 3, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 3, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 3, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
