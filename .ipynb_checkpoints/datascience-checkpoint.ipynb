{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt # Visuals\n",
    "import seaborn as sns \n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split # Create training and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier # Kth Nearest Neighbor\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Trees\n",
    "from sklearn.tree import export_graphviz # Extract Decision Tree visual\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "from sklearn.metrics import roc_curve # ROC Curves\n",
    "from sklearn.metrics import auc # AUC \n",
    "from urllib.request import urlopen # Get data from UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin import of data into the notebook. Because we are working with three different datasets, we had to merge the data into one array. \n",
    "\n",
    "print(data) displays the entire dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cleveland_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "Hungarian_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "Switzerland_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data'\n",
    "np.set_printoptions(threshold=np.nan)#makes it so that we can see a whole array when we output it\n",
    "\n",
    "names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'heartdisease']\n",
    "ClevelandHeartDisease = pd.read_csv(urlopen(Cleveland_data_URL), names = names)#gets Cleveland data\n",
    "HungarianHeartDisease = pd.read_csv(urlopen(Hungarian_data_URL), names = names)#gets Hungary data\n",
    "SwitzerlandHeartDisease = pd.read_csv(urlopen(Switzerland_data_URL), names = names)#gets Switzerland data\n",
    "datatemp = [ClevelandHeartDisease, HungarianHeartDisease, SwitzerlandHeartDisease]#combines all arrays into a list\n",
    "#heartDisease.set_index(['id_number'], inplace = True)\n",
    "#I don't know what that did, but it was from Raoul's code and it was giving me bugs so I got rid of it\n",
    "heartDisease = pd.concat(datatemp)#combines list into one array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin the exploratory analysis of our dataset. \n",
    "\n",
    "We don't want to predict on all the variables so we are getting rid of 'ca', 'slope', and 'thal'.\n",
    "For the variables we kept, there are still some \"?\" in the data, so we're going to replace them with a NAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              int64\n",
       "sex              int64\n",
       "cp               int64\n",
       "trestbps        object\n",
       "chol            object\n",
       "fbs             object\n",
       "restecg         object\n",
       "thalach         object\n",
       "exang           object\n",
       "oldpeak         object\n",
       "heartdisease     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del heartDisease['ca']\n",
    "del heartDisease['slope']\n",
    "del heartDisease['thal']\n",
    "\n",
    "heartDisease = heartDisease.replace('?', np.nan)\n",
    "heartDisease.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loop to count the \"?\" per variable. More for interpretation but we don't really use it. \n",
    "\n",
    "count = 0\n",
    "for item in heartDisease:\n",
    "    for i in heartDisease[item]:\n",
    "        count += (i == '?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin normalizing the data. First the data are all converted to float items and the function \"normalize\" does this!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>heartdisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.218905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.393035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.363184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "0  0.000000    1  0.333333  0.416667  0.218905  0.0      2.0  0.961538    0.0   \n",
       "1  0.021739    1  0.333333  0.333333  0.402985  0.0      0.0  0.769231    0.0   \n",
       "3  0.043478    0  0.000000  0.750000  0.393035  0.0      1.0  0.846154    0.0   \n",
       "4  0.065217    0  0.333333  0.166667  0.363184  0.0      1.0  0.692308    0.0   \n",
       "5  0.086957    0  0.333333  0.208333  0.328358  0.0      0.0  0.807692    0.0   \n",
       "\n",
       "    oldpeak  heartdisease  \n",
       "0  0.342105             0  \n",
       "1  0.342105             0  \n",
       "3  0.342105             0  \n",
       "4  0.342105             0  \n",
       "5  0.342105             0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in heartDisease: #converts everything to floats\n",
    "    heartDisease[item] = pd.to_numeric(heartDisease[item])\n",
    "\n",
    "def normalize(heartDisease, toNormalize): #normalizes \n",
    "    result = heartDisease.copy()\n",
    "    for item in heartDisease.columns:\n",
    "        if (item in toNormalize):\n",
    "            max_value = heartDisease[item].max()\n",
    "            min_value = heartDisease[item].min()\n",
    "            result[item] = (heartDisease[item] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "toNormalize = ['age', 'cp', 'trestbps', 'chol', 'thalach', 'oldpeak'] #columns to normalize\n",
    "heartDisease = normalize(heartDisease, toNormalize)\n",
    "heartDisease = heartDisease.dropna()\n",
    "heartDisease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification problem, so to simplify our project we are going to convert the predictor column into 1 for \"heart disease is present\" and 0 for \"heart disease is not present.\"\n",
    "\n",
    "Before, the scope of the disease ran from 0 - 5 for the intensity of the heart disease but this shit's too hard so we're going to replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    heartDisease['heartdisease'] = heartDisease['heartdisease'].replace(i,1)\n",
    "#heartDisease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function from Ravi that tests for class imbalance in the data. Since we simplified the problem to solely 0's and 1's, this shouldn't be an issue. But let's check.\n",
    "\n",
    "Class Imbalance refers to when a class within a data set is outnumbered by the other class (or classes). Reading documentation online, Class Imbalance is present when a class populates 10-20% of the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of heart disease present is: 42.43%\n",
      "The percentage of heart disease not present is: 57.57%\n"
     ]
    }
   ],
   "source": [
    "def classImbalance(item):\n",
    "    i = 0\n",
    "    n = 0\n",
    "    isPresent = 0 \n",
    "    isNotPresent = 0\n",
    "    for item in heartDisease[item]:\n",
    "        if (item == 1):\n",
    "            i += 1\n",
    "        elif (item == 0):\n",
    "            n += 1\n",
    "    isPresent = (i/len(heartDisease)) * 100\n",
    "    isNotPresent = (n/len(heartDisease)) * 100\n",
    "    print(\"The percentage of heart disease present is: {0:.2f}%\".format(isPresent)) \n",
    "    print(\"The percentage of heart disease not present is: {0:.2f}%\".format(isNotPresent))\n",
    "classImbalance('heartdisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 15))\n",
    "\n",
    "ax.set_axis_bgcolor('#fafafa')\n",
    "plt.title(\"Box Plot of Transformed Data Set\")\n",
    "ax.set(xlim=(-.05, 1.05))\n",
    "ax = sns.boxplot(data = heartDisease[1:29], orient = 'h', palette = 'Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoooo!!! Let's play with some algorithms. First, split the data into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(heartDisease, test_size = 0.20, random_state = 42)\n",
    "# Create the training test omitting the diagnosis\n",
    "\n",
    "training_set = train.ix[:, train.columns != 'heartdisease']\n",
    "# Next we create the class set (Called target in Python Documentation)\n",
    "class_set = train.ix[:, train.columns == 'heartdisease']\n",
    "\n",
    "# Next we create the test set doing the same process as the training set\n",
    "test_set = test.ix[:, test.columns != 'heartDisease']\n",
    "test_class_set = test.ix[:, test.columns == 'heartdisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First applying random forest algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitRF = RandomForestClassifier(random_state = 42, \n",
    "                                criterion='gini',\n",
    "                                n_estimators = 500,\n",
    "                                max_features = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=5, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitRF.fit(train, class_set['heartdisease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to gather the variable importance. This is essential in decision trees and random forests for seeing which attributes played an important role in our algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8,  2,  9,  7,  4,  1,  0,  3,  5,  6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importancesRF = fitRF.feature_importances_\n",
    "indicesRF = np.argsort(importancesRF)[::-1]\n",
    "indicesRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. The feature 'slope' has a Gini Importance of 0.752331\n",
      "2. The feature 'exang' has a Gini Importance of 0.079926\n",
      "3. The feature 'cp' has a Gini Importance of 0.075459\n",
      "4. The feature 'oldpeak' has a Gini Importance of 0.051812\n",
      "5. The feature 'thalach' has a Gini Importance of 0.013988\n",
      "6. The feature 'chol' has a Gini Importance of 0.012730\n",
      "7. The feature 'sex' has a Gini Importance of 0.004122\n",
      "8. The feature 'age' has a Gini Importance of 0.003955\n",
      "9. The feature 'trestbps' has a Gini Importance of 0.003850\n",
      "10. The feature 'fbs' has a Gini Importance of 0.001082\n",
      "11. The feature 'restecg' has a Gini Importance of 0.000746\n"
     ]
    }
   ],
   "source": [
    "namesInd = names[:12]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(11):\n",
    "    i = f\n",
    "    print(\"%d. The feature '%s' has a Gini Importance of %f\" % (f + 1, \n",
    "                                                                namesInd[indicesRF[i]], \n",
    "                                                                importancesRF[indicesRF[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the accuracy of the random forest. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values      0   1\n",
      "Predicted Values        \n",
      "0                 64   0\n",
      "1                  0  50\n"
     ]
    }
   ],
   "source": [
    "predictions_RF = fitRF.predict(test_set)\n",
    "print(pd.crosstab(predictions_RF, test_class_set['heartdisease'], \n",
    "                  rownames=['Predicted Values'], \n",
    "                  colnames=['Actual Values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our mean accuracy on the test set:\n",
      " 100.000 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_RF = fitRF.score(test_set, test_class_set['heartdisease'])\n",
    "\n",
    "print(\"Here is our mean accuracy on the test set:\\n\",\n",
    "     '%.3f' % (accuracy_RF * 100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooooh shit wtf. 100% is hella high......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate for our model is:\n",
      " 0.000 %\n"
     ]
    }
   ],
   "source": [
    "# Here we calculate the test error rate!\n",
    "test_error_rate_RF = 1 - accuracy_RF\n",
    "print(\"The test error rate for our model is:\\n\",\n",
    "     '%.3f' % (test_error_rate_RF * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ROC curve calculation\n",
    "fpr1, tpr1, _ = roc_curve(predictions_RF, test_class_set)\n",
    "#AUC curve calcuation\n",
    "auc_rf = auc(fpr1, tpr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are cool af so let's do this next. \n",
    "\n",
    "My sklearn isn't letting me import the MLP classifier???? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
